{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "from os.path import dirname, join as pjoin\n",
    "import scipy.io as sio\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "data_dir = pjoin(dirname(sio.__file__), 'matlab', 'tests', 'data')\n",
    "X = sio.loadmat(\"ex7data2.mat\")\n",
    "\n",
    "X = X[\"X\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We will code K-means and check its performance against sklearn.kmeans "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How K-means works?\n",
    "\n",
    "1. First it takes some random k-cluster centroids prefeberaly from the given set. E.g. If i want to have three clusters it will take three training examples (here rows). And initialise them as k-centroids. \n",
    "2. Then it will iterate through the dataset and calculate the least_squares_distance for each training example for each initialised k_-centroids and will asign the training example to the k-centroid with least least_squares_distance value. \n",
    "3. Now We have each example (row). Assigned to one of the k-centroids. \n",
    "4. Now we will take the average value of all the training example of the same cluster and assign that average value as the new value for that k-centroid.\n",
    "5. We will calculate the cost function which is the sum of least square distances from step 2. \n",
    "5. Now we will repeat from step 2 with the new averageed k-centroid values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_init(X,no_of_clusters):\n",
    "    K = X[np.random.randint(X.shape[0], size=no_of_clusters), :]\n",
    "    return K\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def K_nearest_assignment(X,K):\n",
    "    #K = random_init(X,no_of_clusters)\n",
    "    Cx = np.zeros((X.shape[0],1))\n",
    "    K_Centroids_Values = np.zeros((X.shape[0],1))\n",
    "    for a in range(X.shape[0]):\n",
    "        for i in range(K.shape[0]):\n",
    "            temp_cent_value = sum((X[a,:] - K[i,:])**2)  \n",
    "            if i == 0:\n",
    "                K_Centroids_Values[a] =  temp_cent_value\n",
    "                Cx[a] = i \n",
    "            if temp_cent_value < K_Centroids_Values[a]:\n",
    "                K_Centroids_Values[a] =  temp_cent_value\n",
    "                Cx[a] = i\n",
    "    J = sum(K_Centroids_Values)/X.shape[0]\n",
    "    K_Centroids_Values\n",
    "    return Cx,J,K_Centroids_Values\n",
    "            \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_assigned_means(X,no_of_clusters,Cx):\n",
    "    dx = np.c_[X,Cx]\n",
    "    dx = pd.DataFrame(dx)\n",
    "    k_means = np.zeros((no_of_clusters,X.shape[1]))\n",
    "    #int_cx = np.unique(Cx)\n",
    "    for i in np.unique(Cx).astype(int):\n",
    "        temp_set = dx[dx.iloc[:,-1]==i]\n",
    "        k_means[i,:] = np.reshape(((np.sum(temp_set,0).values[:-1])/temp_set.shape[0]),(1,X.shape[1]))\n",
    "    return k_means\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def K_means(X,no_of_clusters,no_of_iterations):\n",
    "    K = random_init(X,no_of_clusters)\n",
    "    J = np.zeros((no_of_iterations,1))\n",
    "    Cx = np.zeros((X.shape[0],no_of_iterations))\n",
    "    k_assign = np.zeros((no_of_iterations,no_of_clusters,X.shape[1]))\n",
    "    for i in range(no_of_iterations):\n",
    "        cx, J[i], K_values_j = K_nearest_assignment(X,K)\n",
    "        Cx[:,i] = cx.flatten()\n",
    "        K = k_assigned_means(X,no_of_clusters,cx) #[:,i]\n",
    "        k_assign[i] = k_assigned_means(X,no_of_clusters,cx) #[:,i]\n",
    "        \n",
    "        \n",
    "    return Cx[:,-1]\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m sns\u001b[38;5;241m.\u001b[39mscatterplot(x\u001b[38;5;241m=\u001b[39m\u001b[43mX\u001b[49m[:,\u001b[38;5;241m0\u001b[39m],y \u001b[38;5;241m=\u001b[39mX[:,\u001b[38;5;241m1\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "sns.scatterplot(x=X[:,0],y =X[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is how the data looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After running our K-means with four random initialisation to make sure it does not get stuck in local optima\n",
    "\n",
    "labels = K_means(X,3,20) \n",
    "\n",
    "rows = 2\n",
    "cols = 2\n",
    "fig, ax = plt.subplots(rows, cols, figsize=(10,10))\n",
    "fig.suptitle(\"How K-means converge\", y=1.05, fontsize=24) # Adding  y=1.05, fontsize=24 helped me fix the suptitle overlapping with axes issue\n",
    "for i in range(rows):\n",
    "  for j in range(cols):\n",
    "    sns.scatterplot(ax =ax[i][j], x=X[:,0],y =X[:,1],hue=labels)\n",
    "    \n",
    "plt.setp(ax, xticks=[],yticks=[])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Looks great"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now lets use sklearn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=3, random_state=0).fit(X)\n",
    "sns.scatterplot(x=X[:,0],y =X[:,1],hue=kmeans.labels_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Same results!!!!!!   Hope you like it.!!!! Upvote if you like!!!!!! Cheeers!!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
